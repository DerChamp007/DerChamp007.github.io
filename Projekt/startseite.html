<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Computer Geschichte</title>
    <link rel="stylesheet" href="startseite-style.css">
</head>
<body>

    <nav>
        <ul>
            <li class="dropdown">
                <a href="#">Computer Geschichte</a>
                <div class="dropdown-content">
                    <a href="#">Entstehung</a>
                    <a href="#">Entwicklung</a>
                    <a href="#">Innovationen</a>
                </div>
            </li>
            <li class="dropdown">
                <a href="gamingpc.html">Gaming PC</a>
                <div class="dropdown-content">
                    <a href="gamingpc.html#werkzeuge">Werkzeuge</a>
                    <a href="gamingpc.html#gehäuse">Gehäuse</a>
                    <a href="gamingpc.html#komponenten">Komponenten</a>
                    <a href="gamingpc.html#baugruppe">Baugruppe</a>
                </div>
            </li>
            <li class="dropdown">
                <a href="#">Evolution von Computerspielen</a>
                <div class="dropdown-content">
                    <a href="#">Anfänge</a>
                    <a href="#">Entwicklung</a>
                    <a href="#">Moderne Trends</a>
                </div>
            </li>
            <li><a href="#">Auswirkungen auf die Gesellschaft</a></li>
            <li><a href="#">Kontakt</a></li>
        </ul>
    </nav>
    <div class="container">
        <h1>Computer Geschichte</h1>
    </div>

    <div class="container">
        <h2>Die Vorläufer des mordernen Computers</h2>
        <img src="https://www.pcgameshardware.de/screenshots/original/2012/02/oldpc-12_b2article_artwork.jpg" class="image">

        <p>Die moderne Computertechnologie, wie wir sie heute kennen, entwickelte sich im Vergleich zu anderen Elektrogeräten der Neuzeit sehr schnell. Die Geschichte des Computers reicht bis in die Antike und umfasst weit mehr als nur die modernen Computertechnologien oder mechanische oder elektrische Hilfsmittel (Rechenmaschinen oder Hardware). Zum Beispiel die Entwicklung von Rechenmethoden und -methoden, zum Beispiel für einfache Schreibgeräte auf Papier oder Tafeln.</p>
        <p>Im Folgenden soll ein Überblick über diese Entwicklungen gegeben werden.</p>

        <h2>Die Entwicklung von Zahlen und Ziffern in der Computergeschichte</h2>
        <p>Das Konzept der Zahlen lässt sich nicht direkt auf konkrete Ursprünge zurückführen, wohl aber auf die ersten Notwendigkeiten der Kommunikation zwischen zwei Individuen. In allen bekannten Sprachen gibt es mindestens zwei Zahlen.</p>

        <p>Der Übergang von der reinen Anzahl zur Verwendung mathematischer Rechenoperationen wie Addition, Subtraktion, Multiplikation und Division stellt eine Weiterentwicklung dar. Diese Prozeduren wurden formalisiert (in Formeln dargestellt) und somit überprüft. Daraus entwickelten sich dann weiterführende Betrachtungen, etwa die von Euklid entwickelte Darstellung des größten gemeinsamen Teiles.</p>
        <img src="https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.matheretter.de%2Fimg%2Fwiki%2Fzahlen-schreibweise-entwicklung.png&f=1&nofb=1&ipt=1c073d97ad4ed74cc755c69aff378b929c460b37a938114c25c8e42dab0aa722&ipo=images" class="image2">
        <p>Das arabische Zahlensystem erreichte Europa und ermöglichte eine größere Systematisierung bei der Arbeit mit Zahlen. Die Darstellung von Zahlen, Ausdrücken und Formeln auf Papier ermöglichte die Darstellung von mathematischen Funktionen wie der Quadratwurzel, dem einfachen Logarithmus und trigonometrischen Funktionen. Im Zeitalter von Isaac Newton war Papier und Velin eine wichtige Ressource für Rechenaufgaben, die bis heute an Bedeutung gewonnen hat.</p>
        <br>
        <br>
        <br>
        <h2>Frühzeitige Entwicklung von Rechenmaschinen und -werkzeugen</h2>

        <h3>Der erste Eindruck</h3>
        <p>In rudimentären Ansätzen lässt sich der Abakus mit einem heutigen Computer vergleichen, der vermutlich um 1100 v. Chr. im asiatischen Kulturraum erfunden wurde. Bis in das 17. Jahrhundert wurde der Abakus verwendet und dann durch die ersten Rechenmaschinen ersetzt. In einigen Ländern der Welt wird heute noch der Abakus verwendet. Auch das Rechenbrett des Pythagoras diente einem ähnlichen Zweck.</p>

        <h3>Die Funktionsweise von Antikythera.</h3>
        <p>Das Radwerk von Antikythera wurde vermutlich im 1. Jahrhundert v. Chr. für astronomische Berechnungen konstruiert und verfügte über ein Differentialgetriebe.</p>

        <p>Im Zeitalter der Völkerwanderung endete der technische Fortschritt in Mittel- und Westeuropa fast vollständig, während in den Zeiten der Völkerwanderung viel Wissen verloren ging oder nur noch im oströmischen Reichsteil bewahrt wurde (so etwa das Räderwerk von Antikythera, das erst 1902 wiederentdeckt wurde) oder nur noch im oströmischen Reichsteil erhalten blieb (so beispielsweise das Räderwerk von Antikythera, welches erst 1902 wiederentdeckt wurde, während der Völkerwanderung Die muslimischen Eroberer von Osten und Westen nutzten dieses Wissen und entwickelten es weiter. Die Kreuzzüge und die muslimischen Herrschaften auf der iberischen Halbinsel führten dazu, dass antikes Wissen und die darauf aufbauenden arabischen Erkenntnisse langsam wieder in West- und Mitteleuropa angekommen sind. Ab der Neuzeit begann sich der Motor des technischen Fortschritts wieder zu drehen und beschleunigte ihn bis heute.</p>

        <h2>Der Rechenschieber ist eine der wichtigsten mechanischen Werkzeuge für die Multiplikation und Division.</h2>
        <p>1614 veröffentlichte John Napier die Logarithmentafel. Jost Bürgi ist Mitautor der Logarithmen. Wilhelm Schickard baute 1623 die erste Vier-Spezies-Maschine mit getrennten Werken für Addition/Subtraktion und Multiplikation/Division, womit er zum Begründer der Computergeschichte wurde. Seine Konstruktion beruhte auf dem Zusammenspiel von Zahnrädern, die aus der Uhrmacherkunst stammen und dort eingesetzt wurden. Dadurch erhielt seine Maschine den Namen „Rechenuhr“. Für Johannes Keplers astronomische Berechnungen war ein weiteres Exemplar vorgesehen, doch es wurde unfertig verbrannt. Schickards eigenes Werkzeug ist verschwunden.</p>

        <p>1642 folgte Blaise Pascal mit seiner Zwei-Spezies-Rechenmaschine, die Pascaline. Samuel Morland entwickelte eine Rechenmaschine, die erstmals nicht dezimal multipliziert wurde, sondern auf das englische Geldsystem zugeschnitten war. Gottfried Wilhelm Leibniz baute 1673 seine erste Vierspezies-Maschine und entwickelte 1703 das binäre Zahlensystem (Dualsystem), das später die Grundlage für die Digitalrechner bildete.</p>
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pickett_slide_rule.jpg/330px-Pickett_slide_rule.jpg" class="image1">
        <p>Joseph-Marie Jacquard verwendete Lochkarten, um Webstühle zu steuern. Charles Xavier Thomas de Colmar baute 1820 das „Arithmometer“, den ersten Computer, der in Massenproduktion hergestellt wurde und so den Computer für Großunternehmen erschwinglich machte. Charles Babbage entwickelte zwischen 1820 und 1820 die Differenzmaschine (englisch Difference Engine), konnte sie jedoch aufgrund von Geldmangel und unzureichender Feinmechanik nicht bauen. 1842 bauten Edvard und George Scheutz in Stockholm den ersten mechanischen Computer nach den Ideen von Babbage. Ada Lovelace entwickelte eine Methode zur Programmierung von Computern nach dem Babbage-System und schrieb damit das erste Computerprogramm. Herman Hollerith führte die US-Volkszählung mit Hilfe von Lochkarten durch. 1913 baute Torres y Quevedo eine Schachmaschine mit König und Turm und schuf damit den ersten Spielcomputer.</p>

        <p>Mechanische Rechner wie die Comptometer, der Monroe-Kalkulator und der Addo-X wurden bis in die 1970er Jahre verwendet. Diese Rechner benutzten alle das Dezimalsystem. Das galt sowohl für die Rechner von Charles Babbage um 1800 als auch für den ENIAC von 1945, den ersten vollelektronischen Universalrechner überhaupt.</p>

        <p>Jedoch entstanden auch nichtmechanische Computer, wie beispielsweise der Wasserintegrator.</p>

        <h2>Von 1935 über die Zuse Z1 bis zur Turing-Bombe</h2>

        <p>1935 stellten IBM die IBM 601 vor, eine Lochkartenmaschine, die eine Multiplikation pro Sekunde durchführen konnte. Es wurden ca. 1500 Exemplare verkauft. 1937 meldete Konrad Zuse zwei Patente an, die bereits alle Elemente der so genannten Von-Neumann-Architektur beschreiben. Im selben Jahr baute John Atanasoff zusammen mit dem Doktoranden Clifford Berry einen der ersten Digitalrechner, den Atanasoff-Berry-Computer, und Alan Turing publizierte einen Artikel, der die Turingmaschine, ein abstraktes Modell zur Definition des Algorithmusbegriffs, beschreibt.</p>
        <img src="https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse2.mm.bing.net%2Fth%3Fid%3DOIP.o_Dh3OswPFMTGLHijBIwZwHaGK%26pid%3DApi&f=1&ipt=b37692448b70ed3d7c2c0930caf6538bea3017265bfb6d19507d5dfa9ae8d2c3&ipo=images" class="image">
        <p>1938 stellte Konrad Zuse die Zuse Z1 fertig, einen frei programmierbaren mechanischen Rechner, der allerdings aufgrund von Problemen mit der Fertigungspräzision nie voll funktionstüchtig war. Die Z1 verfügte bereits über Gleitkommarechnung. Sie wurde im Krieg zerstört und später nach Originalplänen neu gefertigt, die Teile wurden auf modernen Fräs- und Drehbänken hergestellt. Dieser Nachbau der Z1, der im Deutschen Technikmuseum in Berlin steht, ist mechanisch voll funktionsfähig und hat eine Rechengeschwindigkeit von 1 Hz, vollzieht also eine Rechenoperation pro Sekunde. Ebenfalls 1938 publizierte Claude Shannon einen Artikel darüber, wie man symbolische Logik mit Relais implementieren kann. (Lit.: Shannon 1938)</p>
        <img src="https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse3.mm.bing.net%2Fth%3Fid%3DOIP.3u6XLruOcLWfXDANeP9u6gHaEK%26pid%3DApi&f=1&ipt=0edd0541c25dafd80ff4146395f0bded6888300f1b0be0aa84bd59670a4d7f43&ipo=images" class="image2">
        <p>Während des Zweiten Weltkrieges gab Alan Turing die entscheidenden Hinweise zur Entzifferung der Enigma-Codes und baute dafür einen speziellen mechanischen Rechner, Turing-Bombe genannt.</p>


        <p><h2>Entwicklung des modernen turingmächtigen Computers</h2></p>
        <h3>Bis zum Ende des Zweiten Weltkrieges</h3>

        <p>Nachbau der Zuse Z3 im Deutschen Museum in München. Ebenfalls im Krieg (1941) baute Konrad Zuse die erste funktionstüchtige programmgesteuerte binäre Rechenmaschine, bestehend aus einer großen Zahl von Relais, die Zuse Z3. Wie 1998 bewiesen werden konnte, war die Z3 turingmächtig und damit außerdem die erste Maschine, die – im Rahmen des verfügbaren Speicherplatzes – beliebige Algorithmen automatisch ausführen konnte. Aufgrund dieser Eigenschaften wird sie oft als erster funktionsfähiger Computer der Geschichte betrachtet. Die nächsten Digitalrechner waren der in den USA gebaute Atanasoff-Berry-Computer (Inbetriebnahme 1941) und die britische Colossus (1941). Sie dienten speziellen Aufgaben und waren nicht turingmächtig. Auch Maschinen auf analoger Basis wurden entwickelt.</p>

        <p>Auf das Jahr 1943 wird auch die angeblich von IBM-Chef Thomas J. Watson stammende Aussage „Ich glaube, es gibt einen weltweiten Bedarf an vielleicht fünf Computern.“ datiert. Im selben Jahr stellte Tommy Flowers mit seinem Team in Bletchley Park den ersten „Colossus“ fertig. 1944 erfolgte die Fertigstellung des ASCC (Automatic Sequence Controlled Computer, „Mark I“ durch Howard H. Aiken) und das Team um Reinold Weber stellte eine Entschlüsselungsmaschine für das Verschlüsselungsgerät M-209 der US-Streitkräfte fertig. Zuse hatte schließlich bis März 1945 seine am 21. Dezember 1943 bei einem Bombenangriff zerstörte Z3 durch die deutlich verbesserte Zuse Z4 ersetzt, den damals einzigen turingmächtigen Computer in Europa, der von 1950 bis 1955 als zentraler Rechner der ETH Zürich genutzt wurde.</p>

        <h2>Nachkriegszeit</h2>
        <p>Das Ende des Zweiten Weltkriegs erlaubte es, dass Europäer und Amerikaner von ihren Fortschritten gegenseitig wieder Kenntnis erlangten. Im Jahr 1946 wurde der Electronical Numerical Integrator and Computer (ENIAC) unter der Leitung von John Eckert und John Mauchly entwickelt und an der Moore School of Electrical Engineering der Universitat von Pennsylvania gebaut. Der ENIAC verfügte über 20 elektronische Register, 3 Funktionstafeln als Festspeicher und bestand aus 18.000 Röhren sowie 1.500 Relais.[4] Der ENIAC ist der erste vollelektronische digitale Universalrechner (Konrad Zuses Z3 verwendete 1941 noch Relais, war also nicht vollelektronisch). 1947 baute IBM den Selective Sequence Electronic Calculator (SSEC), einen Hybridcomputer mit Röhren und mechanischen Relais und die Association for Computing Machinery (ACM) wurde als erste wissenschaftliche Gesellschaft für Informatik gegründet. Im gleichen Jahr wurde auch der erste Transistor realisiert, der heute aus der modernen Technik nicht mehr weggedacht werden kann. Die maßgeblich an der Erfindung beteiligten William B. Shockley, John Bardeen und Walter Brattain erhielten 1956 den Nobelpreis für Physik. In die späten 1940er Jahre fällt auch der Bau des Electronic Discrete Variable Automatic Computer (EDVAC), der erstmals die Von-Neumann-Architektur implementierte.</p>
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Colossus.jpg/220px-Colossus.jpg" class="image">
        <p>Im Jahr 1949 stellte Edmund C. Berkeley, Begründer der ACM, mit „Simon“ den ersten digitalen, programmierbaren Computer für den Heimgebrauch vor. Er bestand aus 50 Relais und wurde in Gestalt von Bauplänen vertrieben, von denen in den ersten zehn Jahren ihrer Verfügbarkeit über 400 Exemplare verkauft wurden. Im selben Jahr stellte Maurice Wilkes mit seinem Team in Cambridge den Electronic Delay Storage Automatic Calculator (EDSAC) vor; basierend auf John von Neumanns EDVAC ist es der erste Rechner, der vollständig speicherprogrammierbar war. Ebenfalls 1949 besichtigte der Schweizer Mathematikprofessor Eduard Stiefel die in einem Pferdestall in Hopferau aufgestellte Zuse Z4 und finanzierte die gründliche Überholung der Maschine durch die Zuse KG, bevor sie an die ETH Zürich ausgeliefert wurde und dort in Betrieb ging.[5]</p>

        <h2>1950er</h2>
        <p>In den 1950er Jahren setzte die Produktion kommerzieller (Serien-)Computer ein. Unter der Leitung von Alwin Walther wurde am Institut für Praktische Mathematik (IPM) der TH Darmstadt ab 1951 der DERA (Darmstädter Elektronischer Rechenautomat) erbaut. Remington Rand baute 1951 ihren ersten kommerziellen Röhrenrechner, den UNIVersal Automatic Computer I (UNIVAC I) und 1955 bei Bell Labs für die US Air Force nimmt der von Jean Howard Felker und L.C. Brown (Charlie Braun) gebaute TRansistorized Airborne DIgital Computer (TRADIC) den ersten Computer der Welt, der komplett mit Transistoren statt Röhren bestückt war den Betrieb auf; im gleichen Jahr begann Heinz Zemanek mit der Konstruktion des ersten auf europäischem Festland gebauten Transistorrechners, des Mailüfterls, das er 1958 der Öffentlichkeit vorstellte.</p>

        <p>Am 30. Dezember 1954[6] vollendet die DDR mit der „OPtik-REchen-MAschine“ (OPREMA) den Bau ihren erstes Computers mit Hilfe von Relais, der zunächst als Doppelrechner aus zwei identischen Systemen redundant ausgelegt wurde. Als klar war, dass die Maschinen stabil arbeiteten, wurden sie in zwei unabhängige Rechner getrennt. Programmierung und Zahleneingabe wurden per Stecktafel vorgenommen, die Ausgabe erfolgte über eine Schreibmaschine.[7] 1956 tauchte der Begriff „Computer“ erstmals in der DDR-Presse auf, nämlich im Zusammenhang mit dem Eniac-„Rechenautomaten“, dessen Akronym für „Electronic Numerical Integrator and Computer“ stand.[8][9] Geläufig wurde der Begriff erst Mitte der 1960er Jahre.</p>

        <p>1956 nahm die ETH Zürich ihre ERMETH in Betrieb und IBM fertigte das erste Magnetplattensystem (Random Access Method of Accounting and Control (RAMAC)). Ab 1958 wurde die Electrologica X1 als volltransistorisierter Serienrechner gebaut. Noch im selben Jahr stellte die Polnische Akademie der Wissenschaften in Zusammenarbeit mit dem Laboratorium für mathematische Apparate unter der Leitung von Romuald Marczynski den ersten polnischen Digital Computer „XYZ“ vor. Vorgesehenes Einsatzgebiet war die Nuklearforschung. 1959 begann Siemens mit der Auslieferung des Siemens 2002, ihres ersten in Serie gefertigten und vollständig auf Basis von Transistoren hergestellten Computers.</p>

        <h2>1960er</h2>
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/IBM_1401_Control_Panel.jpg/220px-IBM_1401_Control_Panel.jpg" class="image3">
        <p>1960 baute IBM den IBM 1401, einen transistorisierten Rechner mit Magnetbandsystem, und DECs (Digital Equipment Corporation) erster Minicomputer, die PDP-1 (Programmierbarer Datenprozessor) erscheint. 1962 lieferte die Telefunken AG die ersten TR 4 aus. 1964 baute DEC den Minicomputer PDP-8 für unter 20.000 Dollar.</p>
        <p>1964 definierte IBM die erste Computerarchitektur S/360, womit Rechner verschiedener Leistungsklassen denselben Code ausführen konnten und bei Texas Instruments wurde der erste „integrierte Schaltkreis“ (IC) entwickelt. 1965 stellte das Moskauer Institut für Präzisionsmechanik und Computertechnologie unter der Leitung seines Chefentwicklers Sergej Lebedjew mit dem BESM-6 den ersten exportfähigen Großcomputer der UdSSR vor. BESM-6 wurde ab 1967 mit Betriebssystem und Compiler ausgeliefert und bis 1987 gebaut. 1966 erschien dann auch noch mit D4a ein 33bit Auftischrechner der TU Dresden.</p>
        <p>Der erste frei programmierbare Tischrechner der Welt, der „Programma 101“ von der Firma Olivetti, erschien 1965 für einen Preis von $3,200(was auf das Jahr 2017 bezogen $24,746entspricht). 1968 bewarb Hewlett-Packard (HP) den HP-9100A in der Science-Ausgabe vom 4. Oktober 1968 als „personal computer“, obgleich diese Bezeichnung nichts mit dem zu tun hat, was seit Mitte der 1970er Jahre bis heute unter einem Personal Computer verstanden wird.</p>
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Olivetti_Programma_101_-_Museo_scienza_e_tecnologia_Milano.jpg/220px-Olivetti_Programma_101_-_Museo_scienza_e_tecnologia_Milano.jpg" class="image">
        <p>Die 1968 entstandene Nixdorf Computer AG erschloss zunächst in Deutschland und Europa, später auch in Nordamerika, einen neuen Computermarkt: die Mittlere Datentechnik bzw. die dezentrale elektronische Datenverarbeitung. Massenhersteller wie IBM setzten weiterhin auf Großrechner und zentralisierte Datenverarbeitung, wobei Großrechner für kleine und mittlere Unternehmen schlicht zu teuer waren und die Großhersteller den Markt der Mittleren Datentechnik nicht bedienen konnten.</p>
        <p>Im Dezember 1968 stellten Douglas C. Engelbart und William English vom Stanford Research Institute (SRI) die erste Computermaus vor, mangels sinnvoller Einsatzmöglichkeit (es gab noch keine grafischen Benutzeroberflächen) interessierte dies jedoch kaum jemanden. 1969 werden die ersten Computer per Internet verbunden.</p>

        <h2>1970er</h2>
        <p>Mit der Erfindung des serienmäßig produzierbaren Mikroprozessors wurden die Computer immer kleiner, leistungsfähiger und preisgünstiger. Doch noch wurde das Potential der Computer verkannt. So sagte noch 1977 Ken Olson, Präsident und Gründer von DEC: „Es gibt keinen Grund, warum jemand einen Computer zu Hause haben wollte.“</p>
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/KL_Intel_C8008-1.jpg/220px-KL_Intel_C8008-1.jpg" class="image4">
        <p>Im Jahr 1971 war es der Hersteller Intel, der mit dem 4004 den ersten in Serie gefertigten Mikroprozessor baute. Er bestand aus 2250 Transistoren. 1971 lieferte Telefunken den TR 440 an das Deutsche Rechenzentrum Darmstadt sowie an die Universitäten Bochum und München. 1972 ging der Illiac IV, ein Supercomputer mit Array-Prozessoren, in Betrieb. 1973 erschien mit Xerox Alto der erste Computer mit Maus, graphischer Benutzeroberfläche (GUI) und eingebauter Ethernet-Karte; und die französische Firma R2E begann mit der Auslieferung des Micral. 1974 stellte HP mit dem HP-65 den ersten programmierbaren Taschenrechner vor und Motorola baute den 6800-Prozessor, währenddessen Intel den 8080-Prozessor fertigte. 1975 begann MITS mit der Auslieferung des Altair 8800. 1975 stellte IBM mit der IBM 5100 den ersten tragbaren Computer vor. Eine Zeichenlänge von 8 Bit und die Einengung der (schon existierenden) Bezeichnung Byte auf dieses Maß wurden in dieser Zeit geläufig.</p>
        <p>1975 Maestro I (ursprünglich Programm-Entwicklungs-Terminal-System PET) von Softlab war weltweit die erste Integrierte Entwicklungsumgebung für Software. Maestro I wurde weltweit 22.000 Mal installiert, davon 6.000 Mal in der Bundesrepublik Deutschland. Maestro I war in den 1970er und 1980er Jahren führend auf diesem Gebiet.</p>
        <p>1976 entwickelte Zilog den Z80-Prozessor und Apple Computer stellte den Apple I vor, den weltweit ersten Personal Computer. 1977 kam der Commodore PET und der Tandy TRS-80 auf den Markt. Der ebenfalls im Jahr 1977 veröffentlichte Apple II gilt bislang als letzter in Serie hergestellter Computer, der von einer einzelnen Person, Steve Wozniak, entworfen wurde. 1978 erschien die VAX-11/780 von DEC, eine Maschine speziell für virtuelle Speicheradressierung. Im gleichen Jahr stellte Intel den 8086 vor, ein 16-Bit-Mikroprozessor; er ist der Urvater der noch heute gebräuchlichen x86-Prozessor-Familie. 1979 schließlich startete Atari den Verkauf seiner Rechnermodelle 400 und 800. Revolutionär war bei diesen, dass mehrere ASIC-Chips den Hauptprozessor entlasteten. </p>

        <h2>1980er</h2>
        <p>Die 1980er waren die Blütezeit der Heimcomputer, zunächst mit 8-Bit-Mikroprozessoren und einem Arbeitsspeicher bis 64 KiB, später auch leistungsfähigere Modelle mit 16-Bit- oder 16/32-Bit-Mikroprozessoren. Eine Eigenentwicklung von Siemens, der Siemens PC 16-10, war dagegen mit einem Anfangspreis von 11.300 DM deutlich zu teuer.</p>
        <p>Das Unternehmen IBM stellte 1981 den IBM-PC vor, legte die Grundkonstruktion offen und schuf einen informellen Industriestandard; sie definierten damit die bis heute aktuelle Geräteklasse der „IBM-PC-kompatiblen Computer“. Dank zahlreicher preiswerter Nachbauten und Fortführungen wurde diese Geräteklasse zu einer der erfolgreichsten Plattformen für den Personal Computer; die heute marktüblichen PCs mit Windows-Betriebssystem und x86-Prozessoren beruhen auf der stetigen Weiterentwicklung des damaligen Entwurfs von IBM.</p>
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/KL_Intel_Pentium_A80501.jpg/220px-KL_Intel_Pentium_A80501.jpg" class="image">
        <p>1982 brachte Intel den 80286-Prozessor auf den Markt und Sun Microsystems entwickelte die Sun-1 Workstation. Nach dem ersten Büro-Computer mit Maus, Lisa, der 1983 auf den Markt kam, wurde 1984 der Apple Macintosh gebaut und setzte neue Maßstäbe für Benutzerfreundlichkeit. Die Sowjetunion konterte mit ihrem „Kronos 1“, einer Bastelarbeit des Rechenzentrums in Akademgorodok. Im Januar 1985 stellte Atari den ST-Computer auf der Consumer Electronics Show (CES) in Las Vegas vor. Im Juli produzierte Commodore den ersten Amiga-Heimcomputer. In Sibirien wurde der „Kronos 2“ vorgestellt, der dann als „Kronos 2.6“ für vier Jahre in Serie ging. 1986 brachte Intel den 80386-Prozessor auf den Markt, 1989 den 80486. Ebenfalls 1986 präsentierte Motorola den 68030-Prozessor. Im gleichen Jahr stellte Acorn den ARM2-Prozessor fertig und setzte ihn im Folgejahr in Acorn-Archimedes-Rechnern ein. 1988 stellte NeXT mit Steve Jobs, Mitgründer von Apple, den gleichnamigen Computer vor.</p>
        <p>Die Computer-Fernvernetzung, deutsch „DFÜ“ (Datenfernübertragung), über das Usenet wurde an Universitäten und in diversen Firmen immer stärker benutzt. Auch Privatleute strebten nun eine Vernetzung ihrer Computer an; Mitte der 1980er Jahre entstanden Mailboxnetze, zusätzlich zum FidoNet das Z-Netz und das MausNet.</p>
        <h2>1990er</h2>
        <p>Die 1990er sind das Jahrzehnt des Internets und des World Wide Web. 1991 spezifizierte das AIM-Konsortium (Apple, IBM, Motorola) die PowerPC-Plattform. 1992 stellte DEC die ersten Systeme mit dem 64-Bit-Alpha-Prozessor vor. 1993 brachte Intel den Pentium-Prozessor auf den Markt, 1995 den Pentium Pro. 1994 stellte Leonard Adleman mit dem TT-100 den ersten Prototyp eines DNA-Computers vor, im Jahr darauf Be Incorporated die BeBox. 1999 baute Intel den Supercomputer ASCI Red mit 9.472 Prozessoren und AMD stellte mit dem Athlon den Nachfolger der K6-Prozessorfamilie vor.</p>
        <h2>Entwicklung im 21. Jahrhundert</h2>
        <p>Zu Beginn des 21. Jahrhunderts sind Computer sowohl in beruflichen wie privaten Bereichen allgegenwärtig und allgemein akzeptiert. Während die Leistungsfähigkeit in klassischen Anwendungsbereichen weiter gesteigert wird, werden digitale Rechner unter anderem in die Telekommunikation und Bildbearbeitung integriert. 2001 baute IBM den Supercomputer ASCI White, und 2002 ging der NEC Earth Simulator in Betrieb. 2003 lieferte Apple den PowerMac G5 aus, den ersten Computer mit 64-Bit-Prozessoren für den Massenmarkt. AMD zog mit dem Opteron und dem Athlon 64 nach.</p>
        <p>2005 produzierten AMD und Intel erste Dual-Core-Prozessoren, 2006 doppelte Intel mit den ersten Core-2-Quad-Prozessoren nach – AMD konnte erst 2007 erste Vierkernprozessoren vorstellen. Bis zum Jahr 2010 stellten mehrere Firmen auch Sechs- und Achtkernprozessoren vor. Entwicklungen wie Mehrkernprozessoren, Berechnung auf Grafikprozessoren (GPGPU) sowie der breite Einsatz von Tablet-Computern dominieren in den letzten Jahren (Stand 2012) das Geschehen.</p>
        <p>Seit den 1980er Jahren stiegen die Taktfrequenzen von anfangs wenigen MHz bis zuletzt (Stand 2015) etwa 4 GHz. In den letzten Jahren konnte der Takt nur noch wenig gesteigert werden, stattdessen wurden Steigerungen der Rechenleistung eher durch mehr Prozessorkerne und vergrößerte Busbreiten erzielt. Auch wenn durch Übertaktung einzelne Prozessoren auf über 8 GHz betrieben werden konnten, sind diese Taktraten auch 2015 noch nicht in Serienprozessoren verfügbar. Außerdem werden zunehmend auch die in Computern verbauten Grafikprozessoren zur Erhöhung der Rechenleistung für spezielle Aufgaben genutzt (z. B. per OpenCL, siehe auch Streamprozessor und GPGPU).</p>
        <p>Seit ca. 2005 spielen auch Umweltaspekte (wie z. B. Stromsparfunktionen von Prozessor und Chipsatz, verringerter Einsatz schädlicher Stoffe) – bei der Produktion, Beschaffung und Nutzung von Computern zunehmend eine Rolle (siehe auch Green IT).</p>
    </div>

        <div class="iframe-container">
            <iframe src="https://derchamp007.github.io/folder/fakeseite2.0.html" ></iframe>
        </div>
</body>
</html>